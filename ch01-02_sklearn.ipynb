{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 지도학습 with labeled data \n",
    "- 분류(Classification)\n",
    "    - 의사결정트리 DecisionTreeClassifier\n",
    "- 회귀(Regression) \n",
    "    - 선형회귀 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter 01 | 파이썬 기반의 머신러닝과 생태계 이해\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = pd.read_csv(\"train.csv\")\n",
    "#titanic_df.describe()\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    491\n",
      "1    216\n",
      "2    184\n",
      "Name: Pclass, dtype: int64\n",
      "Int64Index([3, 1, 2], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "value_counts = titanic_df['Pclass'].value_counts()\n",
    "print(value_counts)  # only defined by series Q1.시리즈의 인덱스틑 어떻게 추출?\n",
    "print(value_counts.index) # A1(pp.57:index객체)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    1\n",
       "2    3\n",
       "3    1\n",
       "4    3\n",
       "Name: Pclass, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_pclass = titanic_df['Pclass']\n",
    "# print(titanic_pclass)\n",
    "# print(type(titanic_pclass))\n",
    "titanic_pclass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_0</th>\n",
       "      <th>Age_by_10</th>\n",
       "      <th>Family_No</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, ...</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings,...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkine...</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2....</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass         Name     Sex   Age  SibSp  Parch       Ticket     Fare Cabin Embarked  Age_0  Age_by_10  Family_No\n",
       "0            1         0       3  Braund, ...    male  22.0      1      0    A/5 21171   7.2500   NaN        S      0      220.0          2\n",
       "1            2         1       1  Cumings,...  female  38.0      1      0     PC 17599  71.2833   C85        C      0      380.0          2\n",
       "2            3         1       3  Heikkine...  female  26.0      0      0  STON/O2....   7.9250   NaN        S      0      260.0          1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df['Age_0']=0\n",
    "#titanic_df.head(3)\n",
    "titanic_df['Age_by_10']=titanic_df['Age']*10\n",
    "titanic_df['Family_No']=titanic_df['SibSp']+titanic_df['Parch']+1\n",
    "titanic_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inplace=False로 drop 후 반환된 값 :  None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, ...</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings,...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkine...</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2....</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass         Name     Sex   Age  SibSp  Parch       Ticket     Fare Cabin Embarked\n",
       "0            1         0       3  Braund, ...    male  22.0      1      0    A/5 21171   7.2500   NaN        S\n",
       "1            2         1       1  Cumings,...  female  38.0      1      0     PC 17599  71.2833   C85        C\n",
       "2            3         1       3  Heikkine...  female  26.0      0      0  STON/O2....   7.9250   NaN        S"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_result = titanic_df.drop(['Age_0','Age_by_10','Family_No'], axis=1, inplace=True)\n",
    "print('inplace=False로 drop 후 반환된 값 : ', drop_result)\n",
    "titanic_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### before axis 0 drop ###\n",
      "   PassengerId  Survived  Pclass         Name     Sex   Age  SibSp  Parch       Ticket     Fare Cabin Embarked\n",
      "0            1         0       3  Braund, ...    male  22.0      1      0    A/5 21171   7.2500   NaN        S\n",
      "1            2         1       1  Cumings,...  female  38.0      1      0     PC 17599  71.2833   C85        C\n",
      "2            3         1       3  Heikkine...  female  26.0      0      0  STON/O2....   7.9250   NaN        S\n",
      "### after axis 0 drop ###\n",
      "     PassengerId  Survived  Pclass         Name     Sex   Age  SibSp  Parch      Ticket     Fare Cabin Embarked\n",
      "3              4         1       1  Futrelle...  female  35.0      1      0      113803  53.1000  C123        S\n",
      "4              5         0       3  Allen, M...    male  35.0      0      0      373450   8.0500   NaN        S\n",
      "5              6         0       3  Moran, M...    male   NaN      0      0      330877   8.4583   NaN        Q\n",
      "6              7         0       1  McCarthy...    male  54.0      0      0       17463  51.8625   E46        S\n",
      "7              8         0       3  Palsson,...    male   2.0      3      1      349909  21.0750   NaN        S\n",
      "..           ...       ...     ...          ...     ...   ...    ...    ...         ...      ...   ...      ...\n",
      "886          887         0       2  Montvila...    male  27.0      0      0      211536  13.0000   NaN        S\n",
      "887          888         1       1  Graham, ...  female  19.0      0      0      112053  30.0000   B42        S\n",
      "888          889         0       3  Johnston...  female   NaN      1      2  W./C. 6607  23.4500   NaN        S\n",
      "889          890         1       1  Behr, Mr...    male  26.0      0      0      111369  30.0000  C148        C\n",
      "890          891         0       3  Dooley, ...    male  32.0      0      0      370376   7.7500   NaN        Q\n",
      "\n",
      "[888 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 12)\n",
    "print('### before axis 0 drop ###')\n",
    "print(titanic_df.head(3))\n",
    "print('### after axis 0 drop ###')\n",
    "drop = titanic_df.drop([0,1,2], axis=0, inplace=False)\n",
    "print(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>Chulmin</td>\n",
       "      <td>2011</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>Eunkyung</td>\n",
       "      <td>2016</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>Jinwoong</td>\n",
       "      <td>2015</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <td>Soobeom</td>\n",
       "      <td>2015</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  Year  Gender\n",
       "one     Chulmin  2011    Male\n",
       "two    Eunkyung  2016  Female\n",
       "three  Jinwoong  2015    Male\n",
       "four    Soobeom  2015    Male"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## pp.64\n",
    "data = {'Name' : ['Chulmin', 'Eunkyung', 'Jinwoong', 'Soobeom'],\n",
    "       'Year' : [2011, 2016, 2015, 2015],\n",
    "       'Gender' : ['Male', 'Female', 'Male', 'Male']\n",
    "       }\n",
    "\n",
    "data_df = pd.DataFrame(data, index=['one', 'two', 'three', 'four'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>276</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Andrews, Miss. Kornelia Theodosia</td>\n",
       "      <td>female</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13502</td>\n",
       "      <td>77.9583</td>\n",
       "      <td>D7</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0000</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                       Name  \\\n",
       "275          276         1       1          Andrews, Miss. Kornelia Theodosia   \n",
       "829          830         1       1  Stone, Mrs. George Nelson (Martha Evelyn)   \n",
       "\n",
       "        Sex   Age  SibSp  Parch  Ticket     Fare Cabin Embarked  \n",
       "275  female  63.0      1      0   13502  77.9583    D7        S  \n",
       "829  female  62.0      0      0  113572  80.0000   B28      NaN  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Boolean Indexting (pp.72)\n",
    "titanic_df = pd.read_csv('train.csv')\n",
    "titanic_boolean = titanic_df[titanic_df['Age']>60]\n",
    "#titanic_boolean\n",
    "# titanic_boolean[['Name', 'Age']].head(3) ## over 2 columns : [[]]\n",
    "# titanic_boolean.loc[:,['Name', 'Age']].head(3)\n",
    "# titanic_df.loc[titanic_df['Age']>60, ['Name', 'Age']].head(3)\n",
    "titanic_df[(titanic_df['Age']>60) & (titanic_df['Pclass']==1) & (titanic_df['Sex']=='female')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>216</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>38.233441</td>\n",
       "      <td>84.154687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184</td>\n",
       "      <td>0.472826</td>\n",
       "      <td>29.877630</td>\n",
       "      <td>20.662183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>491</td>\n",
       "      <td>0.242363</td>\n",
       "      <td>25.140620</td>\n",
       "      <td>13.675550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PassengerId  Survived        Age       Fare\n",
       "Pclass                                             \n",
       "1               216  0.629630  38.233441  84.154687\n",
       "2               184  0.472826  29.877630  20.662183\n",
       "3               491  0.242363  25.140620  13.675550"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sort/Aggregation/Group-by (pp.75)\n",
    "titanic_sorted = titanic_df.sort_values(by=['Pclass','Name'],ascending=False)\n",
    "# titanic_df[['Age', 'Fare']].mean()\n",
    "titanic_groupby = titanic_df.groupby(by='Pclass')\n",
    "# titanic_groupby.count()\n",
    "data = {'Passengers': titanic_groupby['PassengerId'].count(),\n",
    "       'Age' : titanic_groupby['Age'].mean(),\n",
    "        'Survived' : titanic_groupby['Survived'].mean(),\n",
    "        'Fare' : titanic_groupby['Fare'].mean()\n",
    " }\n",
    "Practice = pd.DataFrame(data)\n",
    "# Practice\n",
    "# titanic_groupby = titanic_df.groupby('Pclass')[['PassengerId','Survived']].count()\n",
    "# titanic_groupby = titanic_df.groupby('Pclass')[['PassengerId']].count()\n",
    "# titanic_groupby\n",
    "\n",
    "# titanic_df.groupby('Pclass')['Age'].agg([max, min])\n",
    "agg_format = {'PassengerId':'count', 'Survived':'mean','Age':'mean', 'Fare':'mean'}\n",
    "titanic_df.groupby('Pclass').agg(agg_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Missing Data (pp.79)\n",
    "titanic_df.isna()\n",
    "titanic_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df['Cabin'].fillna('C000', inplace=True)\n",
    "titanic_df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)\n",
    "titanic_df['Embarked'].fillna('S', inplace=True)\n",
    "titanic_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adult      786\n",
       "Child       83\n",
       "Elderly     22\n",
       "Name: Age_Cat, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Apply Lambda (pp.82)\n",
    "titanic_df['Name_len'] = titanic_df['Name'].apply(lambda x : len(x))\n",
    "titanic_df[['Name','Name_len']]\n",
    "\n",
    "titanic_df['Child_Adult'] = titanic_df['Age'].apply(lambda x : 'Child' if x<=15 else 'Adult')\n",
    "titanic_df[['Age', 'Child_Adult']]\n",
    "\n",
    "titanic_df['Age_Cat'] = titanic_df['Age'].apply(lambda x : 'Child' if x<=15 else ('Adult' if x<=60 else 'Elderly'))\n",
    "titanic_df['Age_Cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Young Adult    373\n",
       "Adult          195\n",
       "Student        162\n",
       "Teenager        70\n",
       "Baby            44\n",
       "Child           25\n",
       "Elderly         22\n",
       "Name: Age_Cat, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_category(age):\n",
    "    cat = ''\n",
    "    if age<=5 : cat='Baby'\n",
    "    elif age<=12 : cat='Child'\n",
    "    elif age<=18 : cat='Teenager'\n",
    "    elif age<=25 : cat ='Student'\n",
    "    elif age<=35 : cat = 'Young Adult'\n",
    "    elif age<=60 : cat = 'Adult'\n",
    "    else : cat ='Elderly'\n",
    "    return cat\n",
    "\n",
    "titanic_df['Age_Cat'] = titanic_df['Age'].apply(lambda x : get_category(x))\n",
    "titanic_df[['Age', 'Age_Cat']].head()\n",
    "titanic_df['Age_Cat'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 02 | 사이킷런으로 시작하는 머신러닝\n",
    "\n",
    "## 01. 사이킷런 (scikit-learn, sklearn)\n",
    "- sklearn.datasets : 데이터세트 생성 모듈 모임\n",
    "- sklearn.tree : 트리기반 ML 알고리즘 클래스 모임\n",
    "- sklearn.model_selection : 학습/검증/예측 데이터 분리 및 평가 모듈의 모임\n",
    "\n",
    "cf. 하이퍼 파라미터\n",
    "머신러닝 알고니즘별로 최적의 학습을 위해 직접 입력하는 파라미터들을 통칭, 알고리즘의 성능을 튜닝\n",
    "\n",
    "## 02. 붓꽃 품종 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier # 머신러닝 분류 알고리즘 '의사결정트리클래스'\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "iris = load_iris()\n",
    "# sns.load_dataset(\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'feature_names', 'filename', 'frame', 'target', 'target_names']\n",
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "<class 'list'>\n",
      "\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/datasets/data/iris.csv\n",
      "\n",
      "None\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(dir(iris))\n",
    "print(load_iris().keys())\n",
    "\n",
    "# data : 데이터 가져오기\n",
    "print(iris.data[:5])\n",
    "print(type(iris.data)) \n",
    "print()\n",
    "\n",
    "# feature 레이블 가져오기\n",
    "print(iris.feature_names)\n",
    "print(type(iris.feature_names)) \n",
    "print()\n",
    "\n",
    "# filepath & filename 가져오기\n",
    "print(iris.filename)\n",
    "print()\n",
    "\n",
    "# ???\n",
    "print(iris.frame)\n",
    "print()\n",
    "\n",
    "# 분류할 카데고리 데이터 가져오기\n",
    "print(iris.target)\n",
    "print()\n",
    "\n",
    "# 분류할 카테고리 이름 가져오기\n",
    "print(iris.target_names)\n",
    "print(type(iris.target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     label  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "145      2  \n",
       "146      2  \n",
       "147      2  \n",
       "148      2  \n",
       "149      2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data = iris.data\n",
    "\n",
    "# ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
    "iris_label = iris.target \n",
    "\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "iris_df[\"label\"] = iris.target\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터셋 분류 \n",
    "- 레이블된 데이터셋이 한정되어 있을 때 훈련할 데이터와 테스트할 데이터를 분리시킴\n",
    "\n",
    "| |훈련|테스트|비고|\n",
    "|---|---|---|---|\n",
    "|__정보__|X_train|X_test|sepal/petal_length/width| \n",
    "|__예측__|y_train|y_test|0(setosa), 1(versicolor), 2(virginica)|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size=0.2, random_state=11)\n",
    "# random_state:난수 발생 고정 = seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DecisionTree 객체 할당 및 학습 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=11)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(random_state=11) # random_state:동일한 학습/예측 결과 출력\n",
    "tree.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예측 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 성능 평가\n",
    "- 정확도 : 맞힌 갯수/테스트 데이터 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summary\n",
    "1. 데이터 세트 분리   \n",
    "```\n",
    "    train_test_split(data, label, test_size, random_state)\n",
    "```\n",
    "\n",
    "2. 모델 학습\n",
    "* 객체 생성\n",
    "```\n",
    "    DecisionTreeClassifer(random_state)\n",
    "```\n",
    "* 학습 수행\n",
    "```\n",
    "    fit(train_set)\n",
    "```\n",
    "\n",
    "3. 예측 수행\n",
    "```\n",
    "    predict(test_data)\n",
    "```\n",
    "\n",
    "4. 평가\n",
    "```\n",
    "    accuracy_score(test_label, predict)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. 사이킷런의 기반 프레임워크 익히기\n",
    "\n",
    "- Estimator : 지도학습의 모든 알고리즘을 구현한 클래스\n",
    "    - 메서드 \n",
    "        - fit()\n",
    "        - predict()\n",
    "\n",
    "    - Estimator를 인자로 받는 함수들\n",
    "        - cross_val_score() : 평가 함수\n",
    "        - GridSearchCV() : 하이퍼 파라미터 튜닝을 지원하는 클래스 \n",
    "        \n",
    "        \n",
    "- 비지도학습인 차원 축소, 클러스터링, 피처 추출 등을 구현한 클래스\n",
    "    - 메서드\n",
    "        - fit() : 입력 데이터 형태에 맞춰 데이터를 변환하기 위해 사전 구조를 맞추는 작업으로 지도학습에서의 fit()과는 차이가 있다.  *데이터 전처리? 같은 느낌인가?*   \n",
    "        - transform() : 차원 축소, 클러스터링, 피처 추출 등 실제 작업\n",
    "        - fit_transform() = fit() + transform() but, 사용에 주의 필요!\n",
    "        - predict()\n",
    "        \n",
    "### 사이킷런의 주요 모듈\n",
    "p.94\n",
    "\n",
    "### 내장된 예제 데이터 세트\n",
    "p. 96\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. Model Selection 모듈 소개\n",
    "학습/테스트 데이터 세트 분리, 교차 검증 분할 및 평가, Estimator의 파라미터 튜닝을 위한 함수와 클래스 제공\n",
    "### train_test_split()\n",
    "1. [test] 학습/테스트 데이터 세트를 분리하지 않았을 때\n",
    "    - 결과 : 정확도 100%\n",
    "    - 이유 : 학습한 데이터 기반으로 테스트하였기 때문에"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "train_data = iris.data\n",
    "train_label = iris.target\n",
    "\n",
    "tree.fit(train_data, train_label)\n",
    "\n",
    "pred = tree.predict(train_data)\n",
    "accuracy_score(train_label, pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### train_test_split() 속성\n",
    "- test_size : 전체 데이터 중 테스트 데이터 세트로 얼마나 나눌 것인가(default=0.25)\n",
    "- train_size : \n",
    "- shuffle : 분리하기 전에 데이터를 미리 섞을지, 데이터 분산시켜 효율적인 학습/테스트 데이터 세트 생성 (default=True)\n",
    "- random_state : 동일한 학습/테스트용 데이터 세트를 생성하기 위해서 주어지는 난수값, 값을 지정해주지 않으면 수행할 때마다 다른 학습/테스트용 데이터를 생성\n",
    "- 반환값 : tuple (학습용/테스트용 피처 데이터 세트, 학습용/테스트용 레이블 데이터 세트)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 학습/테스트 데이터 세트를 분리하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_target = iris.target\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size=0.3, random_state=121)\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "pred = tree.predict(X_test)\n",
    "accuracy_score(y_test, pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 검증\n",
    "\n",
    "고정된 학습 데이터와 테스트 데이터로 평가하다보면 테스트 데이터에만 최적의 성능을 발휘하고 새로운 데이터에 대한 예측 성능이 과도하게 떨어지는 과적합(overfitting)이 발생할 수 있다. 이러한 문제점을 개선하기 위해 여러 세트로 구성된 학습 데이터와 검증 데이터 세트에서 학습과 평가를 진행하는 __교차 검증__ 을 이용한다. 테스트 데이터로 예측하기 전에 1차적으로 평가하는 것이다. 각 세트에서 수행한 결과에 따라서 하이퍼 파라미터 튜닝 등 모델 최적화를 더욱 손쉽게 할 수 있다. \n",
    "\n",
    "## K 폴드 교차 검증\n",
    "K 개의 데이터 폴드 세트를 만들어서 K 번만큼 각 폴드 세트에 학습과 검증 평가를 반복적으로 수행\n",
    "- KFold, StratifiedKFold 클래스 사용\n",
    "\n",
    "#### 5 폴드 교차 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 크기 : 150\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "tree = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "# KFold 객체 생성\n",
    "kfold = KFold(n_splits=5)\n",
    "cv_accuracy = []\n",
    "print(\"데이터셋 크기 :\", features.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 정확도 : 1.0, 학습데이터 크기 : 120, 검증데이터 크기 : 30\n",
      "1. 검증 세트 인덱스 : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "2. 정확도 : 0.9667, 학습데이터 크기 : 120, 검증데이터 크기 : 30\n",
      "2. 검증 세트 인덱스 : [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      "3. 정확도 : 0.8667, 학습데이터 크기 : 120, 검증데이터 크기 : 30\n",
      "3. 검증 세트 인덱스 : [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      "4. 정확도 : 0.9333, 학습데이터 크기 : 120, 검증데이터 크기 : 30\n",
      "4. 검증 세트 인덱스 : [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "5. 정확도 : 0.7333, 학습데이터 크기 : 120, 검증데이터 크기 : 30\n",
      "5. 검증 세트 인덱스 : [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "평균 검증 정확도 : 0.90000\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "\n",
    "# KFold 객체의 split() 호출하면 홀드별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    \n",
    "    # kfold.split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    # 학습 및 예측\n",
    "    tree.fit(X_train, y_train)\n",
    "    pred = tree.predict(X_test)\n",
    "    n_iter += 1\n",
    "    \n",
    "    # 반복할 때마다 정확도 측정\n",
    "    acc = np.round(accuracy_score(y_test, pred),4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    \n",
    "    cv_accuracy.append(acc)\n",
    "    \n",
    "    print(\"{}. 정확도 : {}, 학습데이터 크기 : {}, 검증데이터 크기 : {}\".format(n_iter,acc, train_size, test_size))\n",
    "    print(\"{}. 검증 세트 인덱스 : {}\".format(n_iter, test_index))\n",
    "    print()\n",
    "    \n",
    "print(\"평균 검증 정확도 : %.5f\"%np.mean(cv_accuracy))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K 폴드\n",
    "\n",
    "예) 대출 사기 데이터 예측 모델  \n",
    "- 1억건의 데이터 세트 중, 대출 사기 여부를 뜻하는 레이블(사기:1, 정상:0)이 1(사기)인 데이터가 약 1000건. \n",
    "- 전체의 0.0001% 매우 작은 확률로 대출 사기 레이블이 존재.  \n",
    "- K폴드로 랜덤하게 학습 및 테스트 세트의 인덱스를 고르더라고 레이블 값인 0과 1의 비율을 제대로 반영하지 못하는 경우가 발생.  \n",
    "- 1000건씩 나눈다면 사기 데이터가 많을수도 아예 없을 수도 있다. 이럴 경우 모집합의 비율(0.0001%)를 제대로 반영하지 못함.\n",
    "- 대출 사기 레이블이 1인 데이터는 비록 건수는 작지만 대출 사기를 예측하기 위해서는 매우 중요한 피처 값을 가짐.\n",
    "- 따라서 대출 사기 레이블 값의 분포를 학습 및 테스트 세트에서도 유지하는게 중요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     label  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "145      2  \n",
       "146      2  \n",
       "147      2  \n",
       "148      2  \n",
       "149      2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df[\"label\"] = iris.target \n",
    "# iris_df[\"label\"].value_counts()\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 차시\n",
      "학습 레이블 분포 :\n",
      " 2    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "테스트 레이블 분포 :\n",
      " 0    50\n",
      "Name: label, dtype: int64\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "\n",
      "2 차시\n",
      "학습 레이블 분포 :\n",
      " 2    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "테스트 레이블 분포 :\n",
      " 1    50\n",
      "Name: label, dtype: int64\n",
      "[50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73\n",
      " 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
      " 98 99]\n",
      "\n",
      "3 차시\n",
      "학습 레이블 분포 :\n",
      " 1    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "테스트 레이블 분포 :\n",
      " 2    50\n",
      "Name: label, dtype: int64\n",
      "[100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3개의 폴드 세트 구성\n",
    "kfold = KFold(n_splits=3)\n",
    "\n",
    "n_iter = 0\n",
    "for train_index, test_index in kfold.split(features): # iris_df \n",
    "    \n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    \n",
    "    print(n_iter,\"차시\")\n",
    "    print(\"학습 레이블 분포 :\\n\",label_train.value_counts())\n",
    "    print(\"테스트 레이블 분포 :\\n\",label_test.value_counts())\n",
    "    print(test_index)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런 식으로 되면 학습 데이터세트에서 학습되지 않은 레이블 데이터를 입력하면 예측 정확도가 0이 된다.  \n",
    "예를 들어 '2' 레이블이 50개, '1' 레이블이 50개로 구성된 학습 데이터로 학습한 모델은 '0' 레이블을 입력하면 예측 정확도가 0일 것이다.  \n",
    "\n",
    "StratifiedKFold는 이렇게 KFold로 분할된 레이블 데이터 세트가 전체 레이블 값의 분포도를 반영하지 못하는 문제를 해결한다. \n",
    "\n",
    "StratifiedKFold은 KFold와 다르게 레이블 데이터의 분포도에 따라서 학습/검증 데이터를 나누기 때문에 split() 인자로 데이터 세트와 레이블 데이터 세트도 반드시 필요하다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 차 검증\n",
      "학습 레이블 분포: [0 1 2] [40 40 40]\n",
      "테스트 레이블 분포: [0 1 2] [10 10 10]\n",
      "\n",
      "2 차 검증\n",
      "학습 레이블 분포: [0 1 2] [40 40 40]\n",
      "테스트 레이블 분포: [0 1 2] [10 10 10]\n",
      "\n",
      "3 차 검증\n",
      "학습 레이블 분포: [0 1 2] [40 40 40]\n",
      "테스트 레이블 분포: [0 1 2] [10 10 10]\n",
      "\n",
      "4 차 검증\n",
      "학습 레이블 분포: [0 1 2] [40 40 40]\n",
      "테스트 레이블 분포: [0 1 2] [10 10 10]\n",
      "\n",
      "5 차 검증\n",
      "학습 레이블 분포: [0 1 2] [40 40 40]\n",
      "테스트 레이블 분포: [0 1 2] [10 10 10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# numpy array\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in skf.split(features, label):\n",
    "    n_iter += 1\n",
    "    label_train = label[train_index]\n",
    "    label_test = label[test_index]\n",
    "    \n",
    "    train_unique, train_cnts = np.unique(label_train, return_counts=True)\n",
    "    test_unique, test_cnts = np.unique(label_test, return_counts=True)\n",
    "    \n",
    "    print(n_iter,\"차 검증\")\n",
    "    print(\"학습 레이블 분포:\", train_unique, train_cnts)\n",
    "    print(\"테스트 레이블 분포:\", test_unique, test_cnts)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 차 검증\n",
      "학습 데이터 분포 : \n",
      " 2    34\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "테스트 데이터 분포 : \n",
      " 1    17\n",
      "0    17\n",
      "2    16\n",
      "Name: label, dtype: int64\n",
      "테스트 데이터 인덱스 : \n",
      " [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
      "\n",
      "2 차 검증\n",
      "학습 데이터 분포 : \n",
      " 1    34\n",
      "2    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "테스트 데이터 분포 : \n",
      " 2    17\n",
      "0    17\n",
      "1    16\n",
      "Name: label, dtype: int64\n",
      "테스트 데이터 인덱스 : \n",
      " [ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
      "\n",
      "3 차 검증\n",
      "학습 데이터 분포 : \n",
      " 0    34\n",
      "2    33\n",
      "1    33\n",
      "Name: label, dtype: int64\n",
      "테스트 데이터 분포 : \n",
      " 2    17\n",
      "1    17\n",
      "0    16\n",
      "Name: label, dtype: int64\n",
      "테스트 데이터 인덱스 : \n",
      " [ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pandas DataFrame\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df, iris_df[\"label\"]):\n",
    "    \n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df[\"label\"].iloc[test_index]\n",
    "    \n",
    "    print(n_iter,\"차 검증\")\n",
    "    print(\"학습 데이터 분포 : \\n\", label_train.value_counts())\n",
    "    print(\"테스트 데이터 분포 : \\n\", label_test.value_counts())\n",
    "    print(\"테스트 데이터 인덱스 : \\n\", test_index)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    50\n",
      "1    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "1    17\n",
      "0    17\n",
      "2    16\n",
      "dtype: int64\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
      "2    17\n",
      "0    17\n",
      "1    16\n",
      "dtype: int64\n",
      "[ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
      "2    17\n",
      "1    17\n",
      "0    16\n",
      "dtype: int64\n",
      "[ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "[0.98, 0.94, 0.98]\n",
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# StratifiedKFold 이용해서 붓꽃 데이터 교차 검증하기\n",
    "tree = DecisionTreeClassifier(random_state = 156)\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=3)\n",
    "n_iter = 0\n",
    "cv_acc = []\n",
    "\n",
    "print(iris_df['label'].value_counts())\n",
    "\n",
    "for train_idx, test_idx in skfold.split(iris_df, iris_df['label']):\n",
    "    \n",
    "    n_iter += 1\n",
    "    X_train, X_test = features[train_idx], features[test_idx]\n",
    "    y_train, y_test = label[train_idx], label[test_idx]\n",
    "    \n",
    "    tree.fit(X_train, y_train)\n",
    "    pred = tree.predict(X_test)\n",
    "    acc = np.round(accuracy_score(y_test, pred), 5)\n",
    "    cv_acc.append(acc)\n",
    "    \n",
    "    print(pd.DataFrame(y_test).value_counts())\n",
    "    print(test_idx)\n",
    "\n",
    "print(cv_acc)\n",
    "print(np.mean(cv_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross_val_score()\n",
    "```\n",
    "sklearn.model_selection.cross_val_score(estimator, X, y=None, *, groups=None, scoring=None, cv=None, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', error_score=nan)\n",
    "```\n",
    "\n",
    "#### 주요 인자\n",
    "`estimator`:회귀/분류, `X`:피처 데이터, `y`:레이블 데이터, `scoring`:예측성능 평가지표, `cv`:폴드수\n",
    "  \n",
    "cf. estimator에 <U>분류 모델</U>이 들어가면 __Stratified KFold__ 방식으로 학습/테스트 데이터셋 분할,\n",
    "<U>회귀 모델</U>이라면 __KFold__ 방식\n",
    "\n",
    "#### cross_validate() \n",
    "여러 개의 평가 지표를 반환할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98 0.94 0.98]\n",
      "<class 'numpy.ndarray'>\n",
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "tree = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "scores = cross_val_score(tree, data, label, scoring='accuracy', cv=3)\n",
    "print(scores)\n",
    "print(type(scores))\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV\n",
    "- 교차 검증과 최적 하이퍼 파라미터 튜닝을 한번에  \n",
    "- 분류와 회귀 알고리즘에 사용되는 하이퍼 파라비터를 순차적으로 입력하면서 편리하게 최적의 파라미터를 도출할 수 있는 방안을 제공\n",
    "\n",
    "```\n",
    "class sklearn.model_selection.GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
    "```\n",
    "#### 주요 인자\n",
    "\n",
    "- `estimator`: 분류/회귀/파이프라인?\n",
    "- `param_grid`:튜닝을 위한 파라미터와 그 값\n",
    "- `scoring`:예측 성능 평가 방법\n",
    "- `cv` : 학습/테스트 세트의 개수\n",
    "- `refilt`(default=True) : 가장 최적의 하이퍼 파라미터를 찾은 뒤 입력된 estimator 객체를 해당 하이퍼파라미터로 재학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = {'max_depth':[1,2,3], 'min_samples_split':[2,3]} # 2*3=6회에 걸쳐 최적의 파라미터\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 붓꽃데이터 예측 분석하기\n",
    "- train_test_split()을 이용해 학습/테스트 데이터 분리\n",
    "- 학습 데이터에서 GridSearchCV를 이용해서 최적 하이퍼 파라미터 추출\n",
    "- DecisionTreeClassifier의 중요 하이퍼 파라미터인 max_depth와 min_samples_split 값을 변화시키면서 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "iris_data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.2, random_state=121)\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "params = {'max_depth':[1,2,3], 'min_samples_split':[2,3]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*DecisionTreeClassifier을 이루는 max_depth나 min_samples_split 같은 하이퍼 파라미터에 대해서 알아보아야겠다... 잘 감이 오지 않는다.. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# pram_grid의 하이퍼 파라미터를 3개의 train, test set fold로 나누어 테스트 수행 설정\n",
    "grid_dtree = GridSearchCV(dtree, param_grid=params, cv=3, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>7.661917e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>3.698691e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000720</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>2.872413e-05</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3.118048e-02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>1.796579e-05</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3.118048e-02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>1.798266e-06</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>2.041241e-02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>7.867412e-07</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>2.041241e-02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.000794      0.000105         0.000420    7.661917e-05   \n",
       "1       0.000518      0.000006         0.000337    3.698691e-06   \n",
       "2       0.000720      0.000044         0.000400    2.872413e-05   \n",
       "3       0.000349      0.000148         0.000149    1.796579e-05   \n",
       "4       0.000230      0.000010         0.000130    1.798266e-06   \n",
       "5       0.000219      0.000003         0.000127    7.867412e-07   \n",
       "\n",
       "  param_max_depth param_min_samples_split  \\\n",
       "0               1                       2   \n",
       "1               1                       3   \n",
       "2               2                       2   \n",
       "3               2                       3   \n",
       "4               3                       2   \n",
       "5               3                       3   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}              0.700   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}              0.700   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}              0.925   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}              0.925   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}              0.975   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}              0.975   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0                0.7               0.70         0.700000    1.110223e-16   \n",
       "1                0.7               0.70         0.700000    1.110223e-16   \n",
       "2                1.0               0.95         0.958333    3.118048e-02   \n",
       "3                1.0               0.95         0.958333    3.118048e-02   \n",
       "4                1.0               0.95         0.975000    2.041241e-02   \n",
       "5                1.0               0.95         0.975000    2.041241e-02   \n",
       "\n",
       "   rank_test_score  \n",
       "0                5  \n",
       "1                5  \n",
       "2                3  \n",
       "3                3  \n",
       "4                1  \n",
       "5                1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 붓꽃 학습 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습/평가\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "# GridSearchCV 결과를 추출해 DataFrame으로 변환\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score',\n",
    "          'split0_test_score','split1_test_score','split2_test_score']]\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- best_params : 최고 성능을 나타낸 하이퍼 파라미터의 값\n",
    "- best_score_ : 평가 결과 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_check_is_fitted',\n",
       " '_check_n_features',\n",
       " '_estimator_type',\n",
       " '_format_results',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_pairwise',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_required_parameters',\n",
       " '_run_search',\n",
       " '_validate_data',\n",
       " 'best_estimator_',\n",
       " 'best_index_',\n",
       " 'best_params_',\n",
       " 'best_score_',\n",
       " 'classes_',\n",
       " 'cv',\n",
       " 'cv_results_',\n",
       " 'decision_function',\n",
       " 'error_score',\n",
       " 'estimator',\n",
       " 'fit',\n",
       " 'get_params',\n",
       " 'iid',\n",
       " 'inverse_transform',\n",
       " 'multimetric_',\n",
       " 'n_features_in_',\n",
       " 'n_jobs',\n",
       " 'n_splits_',\n",
       " 'param_grid',\n",
       " 'pre_dispatch',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'refit',\n",
       " 'refit_time_',\n",
       " 'return_train_score',\n",
       " 'score',\n",
       " 'scorer_',\n",
       " 'scoring',\n",
       " 'set_params',\n",
       " 'transform',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(grid_dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_dtree.best_params_ # 하이퍼 파라미터 최적값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_dtree.best_score_ # 최고 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# 최적 성능을 나타내는 하이퍼 파라미터로 학습해 저장\n",
    "estimator = grid_dtree.best_estimator_\n",
    "\n",
    "# GridSearchCV의 best_estimator_는 이미 최적 학습이 됐으므로 별도 학습이 필요 없음\n",
    "pred = estimator.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 학습 데이터를 GridSearchCV를 이용해 최적 하이퍼 파라미터 튜닝을 수행한 뒤에 별도의 테스트 세트에서 이를 평가하는 것이 일반적인 머신러닝 모델 적용 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. 데이터 전처리\n",
    "### 1. 데이터 인코딩\n",
    "### 레이블 인코딩\n",
    "`LabelEncoder`로 객체 생성 후 fit(), transform()을 호출해 레이블 인코딩 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 4 5 3 3 2 2]\n",
      "['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n",
      "['전자레인지' '컴퓨터' 'TV' '믹서' '냉장고']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items = ['TV', '냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "print(labels)\n",
    "print(encoder.classes_)\n",
    "print(encoder.inverse_transform([4,5,0,2,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_check_n_features', '_get_param_names', '_get_tags', '_more_tags', '_repr_html_', '_repr_html_inner', '_repr_mimebundle_', '_validate_data', 'classes_', 'fit', 'fit_transform', 'get_params', 'inverse_transform', 'set_params', 'transform']\n"
     ]
    }
   ],
   "source": [
    "print(dir(encoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블 인코딩으 간단하게 문자열 값을 숫자형 카테고리 값으로 반환하는데,\n",
    "ML 알고리즘에서 숫자의 대소비교를 이용해서 특정 레이블에 대해서 가중치줄 수 있다. 이러한 문제를 해결하기 위해서 원-핫 인코딩을 사용\n",
    "\n",
    "### 원-핫 인코딩\n",
    "피처의 고유값을 열 형태로 차원을 변환한 뒤, 고유 값에 해당하는 1을 표시하고 나머지 칼럼에는 0을 표시한다.\n",
    "*class18_0629_review.ipynb*\n",
    "\n",
    "| data | bit 1 | bit 2 | bit 3 | bit 4 |category|\n",
    "|---|---|---|---|---|---|\n",
    "|data1|1|0|0|0|→ category1|\n",
    "|data2|0|1|0|0|→ category2|\n",
    "|data3|0|0|1|0|→ category3|\n",
    "|data4|0|0|0|1|→ category4|\n",
    "\n",
    "`OneHotEncoder`을 사용하기 전에 문자열 값을 숫자형으로 변환해야하며, 두번째 입력값으로 2차원 데이터를 입력해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "(8, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "# 숫자형으로 변환하기 위해서 LabelEncoder 사용\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "\n",
    "# 2차원 데이로 변환\n",
    "labels = labels.reshape(-1,1)\n",
    "\n",
    "# 원핫인코딩\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(labels)\n",
    "oh_labels = oh_encoder.transform(labels)\n",
    "\n",
    "print(oh_labels.toarray())\n",
    "print(oh_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_check_X', '_check_n_features', '_compute_drop_idx', '_fit', '_get_feature', '_get_param_names', '_get_tags', '_more_tags', '_repr_html_', '_repr_html_inner', '_repr_mimebundle_', '_transform', '_validate_data', '_validate_keywords', 'categories', 'categories_', 'drop', 'drop_idx_', 'dtype', 'fit', 'fit_transform', 'get_feature_names', 'get_params', 'handle_unknown', 'inverse_transform', 'set_params', 'sparse', 'transform']\n"
     ]
    }
   ],
   "source": [
    "print(dir(oh_encoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_dummies()\n",
    "- pandas에서 원핫인코딩을 더 쉽게 지원하는 API\n",
    "- OneHotEncoder와 다르게 문자열 카테고리 값을 숫자형으로 변환할 필요 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>items_TV</th>\n",
       "      <th>items_냉장고</th>\n",
       "      <th>items_믹서</th>\n",
       "      <th>items_선풍기</th>\n",
       "      <th>items_전자레인지</th>\n",
       "      <th>items_컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   items_TV  items_냉장고  items_믹서  items_선풍기  items_전자레인지  items_컴퓨터\n",
       "0         1          0         0          0            0          0\n",
       "1         0          1         0          0            0          0\n",
       "2         0          0         0          0            1          0\n",
       "3         0          0         0          0            0          1\n",
       "4         0          0         0          1            0          0\n",
       "5         0          0         0          1            0          0\n",
       "6         0          0         1          0            0          0\n",
       "7         0          0         1          0            0          0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'items':['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']})\n",
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 피처 스케일링\n",
    "서로 다른 변수의 값 범위를 일정한 수준으로 작업\n",
    "### 표준화\n",
    "- 데이터의 피처 각각이 평균이 0이고 분산이 1인 가우시안 정규 분포를 가진 값으로 변환됨\n",
    "$ x_{i,new} = \\frac{x_{i}-mean(x)}{std(x)} \\\\\n",
    "x_{i,new} = standardized x_{i}$\n",
    "\n",
    "\n",
    "### 정규화\n",
    "- 서로 다른 피처의 크기를 통일하기 위해 크기를 변환해줌\n",
    "$ x_{i,new} = \\frac{x_{i}-min(x)}{max(x)-min(x)} \\\\\n",
    "x_{i,new} = normalized x_{i}$\n",
    "\n",
    "### StandardScaler \n",
    "- 표준화 지원 클래스\n",
    "- 개별 피처를 평균이 0이고, 분산이 1인 값으로 변환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64\n",
      "\n",
      "sepal length (cm)    0.685694\n",
      "sepal width (cm)     0.189979\n",
      "petal length (cm)    3.116278\n",
      "petal width (cm)     0.581006\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "\n",
    "print(iris_df.mean()) # feature별로 평균\n",
    "print()\n",
    "print(iris_df.var()) # feature별로 분산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm)   -1.690315e-15\n",
      "sepal width (cm)    -1.842970e-15\n",
      "petal length (cm)   -1.698641e-15\n",
      "petal width (cm)    -1.409243e-15\n",
      "dtype: float64\n",
      "\n",
      "sepal length (cm)    1.006711\n",
      "sepal width (cm)     1.006711\n",
      "petal length (cm)    1.006711\n",
      "petal width (cm)     1.006711\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler() # StandardScaler 객체 생성\n",
    "scaler.fit(iris_df) # 데이터 세트 입력\n",
    "iris_scaled = scaler.transform(iris_df) # 데이터 세트(ndarray)로 호출\n",
    "\n",
    "iris_df_scaled = pd.DataFrame(data = iris_scaled, columns = iris.feature_names)\n",
    "print(iris_df_scaled.mean()) # feature별로 평균\n",
    "print()\n",
    "print(iris_df_scaled.var()) # feature별로 분산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler\n",
    "- 데이터값을 0과 1사이의 범위 값으로 변환, 음수 값이 있다면 -1에서 1값으로 변환\n",
    "- 입력된 데이터의 최댓값과 최솟값을 기준으로 0~1로 축소시키는 것 같다.  \n",
    "$x_{new} = \\frac{x-min}{max-min} \\\\ if x=max, x_{new}=1 \\\\ if x=min, x_{new}=0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm)    0.0\n",
      "sepal width (cm)     0.0\n",
      "petal length (cm)    0.0\n",
      "petal width (cm)     0.0\n",
      "dtype: float64\n",
      "\n",
      "sepal length (cm)    1.0\n",
      "sepal width (cm)     1.0\n",
      "petal length (cm)    1.0\n",
      "petal width (cm)     1.0\n",
      "dtype: float64\n",
      "\n",
      "sepal length (cm)    0.428704\n",
      "sepal width (cm)     0.440556\n",
      "petal length (cm)    0.467458\n",
      "petal width (cm)     0.458056\n",
      "dtype: float64\n",
      "\n",
      "sepal length (cm)    0.052908\n",
      "sepal width (cm)     0.032983\n",
      "petal length (cm)    0.089522\n",
      "petal width (cm)     0.100869\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler() # 객체 생성\n",
    "scaler.fit(iris_df) # 데이터 세트 입력\n",
    "iris_scaled = scaler.transform(iris_df) # 데이터 세트(ndarray)로 호출\n",
    "\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns = iris.feature_names)\n",
    "print(iris_df_scaled.min())\n",
    "print()\n",
    "print(iris_df_scaled.max())\n",
    "print()\n",
    "print(iris_df_scaled.mean())\n",
    "print()\n",
    "print(iris_df_scaled.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 데이터와 테스트 데이터의 스케일링 변환시 유의점\n",
    "- 학습 데이터로 fit()을 적용한 결과를 이용해서 테스트 데이터에 transform()을 시켜야한다. 테스트 데이터에 fit()을 적용하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      "\n",
      "[0 1 2 3 4 5]\n",
      "[0.  0.2 0.4 0.6 0.8 1. ]\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터에 fit을 적용할 경우\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# 학습 데이터는 0~10, 테스트 데이터는 0~5\n",
    "train_array = np.arange(0,11).reshape(-1,1)\n",
    "test_array = np.arange(0,6).reshape(-1,1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_array) \n",
    "train_scaled = scaler.transform(train_array) # 1/10 scale로 변환 : 10 → 1\n",
    "\n",
    "print(np.round(train_array.reshape(-1),2))\n",
    "print(np.round(train_scaled.reshape(-1),2))\n",
    "print()\n",
    "\n",
    "# 학습 데이터를 fit\n",
    "scaler.fit(test_array)\n",
    "test_scaled = scaler.transform(test_array) # 1/5 scale로 변환 : 5 → 1\n",
    "\n",
    "print(np.round(test_array.reshape(-1),2))\n",
    "print(np.round(test_scaled.reshape(-1),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      "[0.  0.1 0.2 0.3 0.4 0.5]\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터와 테스트 데이터를 동일한 fit()에 적용하기\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_array)\n",
    "train_scaled = scaler.transform(train_array)\n",
    "test_scaled = scaler.transform(test_array)\n",
    "\n",
    "print(train_scaled.reshape(-1))\n",
    "print(test_scaled.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      "[0.  0.1 0.2 0.3 0.4 0.5]\n"
     ]
    }
   ],
   "source": [
    "# fit_transfrom() 사용하기\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train_array)\n",
    "test_scaled = scaler.transform(test_array)\n",
    "\n",
    "print(train_scaled.reshape(-1))\n",
    "print(test_scaled.reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 스케일링 변환 과정에서의 제안\n",
    "1. 가능하다면 전체 테이터의 스케일링 변환을 적용한 뒤 학습과 테스트 데이터로 분리\n",
    "2. 1이 여의치 않다면 테스트 데이터 변환 시에는 fit(), fit_transform() 사용 X, 학습 데이터로 이미 fit()된 scaler 객체를 이용해서 transform()으로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. 사이킷런으로 수행하는 타이타닉 생존자 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_df = pd.read_csv(\"./titanic_train.csv\")\n",
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Age, Cabin, Embarked 결측치 처리\n",
    "titanic_df['Age'].fillna(titanic_df[\"Age\"].mean(), inplace=True)\n",
    "titanic_df['Cabin'].fillna('N', inplace=True)\n",
    "titanic_df['Embarked'].fillna('N', inplace=True)\n",
    "\n",
    "titanic_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n",
      "\n",
      "N              687\n",
      "G6               4\n",
      "B96 B98          4\n",
      "C23 C25 C27      4\n",
      "F33              3\n",
      "              ... \n",
      "A7               1\n",
      "C82              1\n",
      "C7               1\n",
      "C104             1\n",
      "C99              1\n",
      "Name: Cabin, Length: 148, dtype: int64\n",
      "\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "N      2\n",
      "Name: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(titanic_df['Sex'].value_counts())\n",
    "print()\n",
    "print(titanic_df['Cabin'].value_counts())\n",
    "print()\n",
    "print(titanic_df['Embarked'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    N\n",
       "1    C\n",
       "2    N\n",
       "3    C\n",
       "4    N\n",
       "Name: Cabin, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df['Cabin'] = titanic_df['Cabin'].str[:1]\n",
    "titanic_df['Cabin'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">female</th>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">male</th>\n",
       "      <th>0</th>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Survived\n",
       "Sex    Survived          \n",
       "female 0               81\n",
       "       1              233\n",
       "male   0              468\n",
       "       1              109"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 성별에 따른 생존자수\n",
    "titanic_df.groupby(['Sex',\"Survived\"])[['Survived']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Sex', ylabel='Survived'>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUG0lEQVR4nO3df7BcZ33f8ffH16geG2NKfFtTyY5VEDgmtQ0WInRIMEkMMk0rKKT4R+uYkGjUIugvozhN47Q4NIPdMgmxHFVlVCedDAodUyJSJQohiUNNaHXd+JdsRG8lsK5klSvcgO0wGNnf/rFrd713r7S29dxr6bxfMzt3n3OePfuVtNJH59lznidVhSSpu05a7AIkSYvLIJCkjjMIJKnjDAJJ6jiDQJI67uTFLuDZOvPMM+vcc89d7DIk6bhy5513HqqqyVH7jrsgOPfcc5mamlrsMiTpuJLka/Ptc2hIkjrOIJCkjjMIJKnjDAJJ6rimQZBkdZLdSaaTXDdi/xlJPpvk7iS7kry3ZT2SpLmaBUGSCWAjcBlwPnBFkvOHur0fuL+qLgQuAf5dkiWtapIkzdXyjGAVMF1Ve6rqcWArsGaoTwGnJwnwYuBh4HDDmiRJQ1oGwVJg30B7pr9t0M3A9wEHgHuBf1xVTw4fKMnaJFNJpmZnZ1vVK0md1DIIMmLb8OIHbwPuAv4acBFwc5KXzHlR1eaqWllVKycnR94YJ+kEsmHDBq6++mo2bNiw2KV0QssgmAHOHmgvo/c//0HvBT5dPdPAXuC8hjVJOg4cPHiQ/fv3c/DgwcUupRNaBsFOYEWS5f0vgC8Htg31eRD4EYAkfxV4NbCnYU2SpCHN5hqqqsNJ1gM7gAlgS1XtSrKuv38TcANwa5J76Q0l/UxVHWpVkyRprqaTzlXVdmD70LZNA88PAG9tWYMk6ci8s1iSOs4gkKSOMwgkqeMMAknqOINAkjrOIJCkjjMIJKnjDAJJ6jiDQJI6rumdxZKenQc//DcWu4QXhMMPvww4mcMPf83fE+Cc6+9tenzPCCSp4wwCSeo4g0CSOs4gkKSOMwgkqeMMAknqOINAkjquaRAkWZ1kd5LpJNeN2P+hJHf1H/cleSLJy1rWJEl6pmZBkGQC2AhcBpwPXJHk/ME+VXVTVV1UVRcBPwvcXlUPt6pJkjRXyzOCVcB0Ve2pqseBrcCaI/S/Avhkw3okSSO0DIKlwL6B9kx/2xxJTgVWA7fNs39tkqkkU7Ozs8e8UEnqspZBkBHbap6+fxu4Y75hoaraXFUrq2rl5OTkMStQktR20rkZ4OyB9jLgwDx9L8dhIUl9Z57yJHC4/1OttQyCncCKJMuB/fT+sb9yuFOSM4A3A3+/YS2SjiPXXvDni11CpzQLgqo6nGQ9sAOYALZU1a4k6/r7N/W7vhP4/ap6rFUtkqT5NV2PoKq2A9uHtm0aat8K3NqyDknS/LyzWJI6ziCQpI4zCCSp4wwCSeo4g0CSOs4gkKSOMwgkqeMMAknqOINAkjrOIJCkjjMIJKnjDAJJ6jiDQJI6ziCQpI4zCCSp4wwCSeo4g0CSOq5pECRZnWR3kukk183T55IkdyXZleT2lvVIkuZqtlRlkglgI3ApMAPsTLKtqu4f6PNS4BZgdVU9mOSvtKpHkjRayzOCVcB0Ve2pqseBrcCaoT5XAp+uqgcBqurrDeuRJI3QMgiWAvsG2jP9bYNeBfzlJH+c5M4kV486UJK1SaaSTM3OzjYqV5K6qWUQZMS2GmqfDFwM/C3gbcDPJ3nVnBdVba6qlVW1cnJy8thXKkkd1uw7AnpnAGcPtJcBB0b0OVRVjwGPJfkT4ELgKw3rkiQNaHlGsBNYkWR5kiXA5cC2oT6/DfxgkpOTnAq8AXigYU2SpCHNzgiq6nCS9cAOYALYUlW7kqzr799UVQ8k+T3gHuBJ4BNVdV+rmiRJc7UcGqKqtgPbh7ZtGmrfBNzUsg5J0vy8s1iSOs4gkKSOMwgkqeMMAknqOINAkjrOIJCkjjMIJKnjDAJJ6jiDQJI6ziCQpI4zCCSp4wwCSeo4g0CSOs4gkKSOMwgkqeMMAknqOINAkjquaRAkWZ1kd5LpJNeN2H9Jkm8muav/uL5lPZKkuZotVZlkAtgIXArMADuTbKuq+4e6fqGqfqxVHZKkI2t5RrAKmK6qPVX1OLAVWNPw/SRJz0HLIFgK7Btoz/S3DXtjkruT/G6S14w6UJK1SaaSTM3OzraoVZI6q2UQZMS2Gmr/T+B7q+pC4FeBz4w6UFVtrqqVVbVycnLy2FYpSR3XMghmgLMH2suAA4MdqupbVfVo//l24EVJzmxYkyRpSMsg2AmsSLI8yRLgcmDbYIckZyVJ//mqfj3faFiTJGnIEa8aSvIIc4dznlZVLznCvsNJ1gM7gAlgS1XtSrKuv38T8G7gHyY5DHwbuLyq5n0/SdKxd8QgqKrTAZJ8GDgI/Cd6Y/9XAacf7eD94Z7tQ9s2DTy/Gbj5WVctSTpmxh0aeltV3VJVj/TH9X8NeFfLwiRJC2PcIHgiyVVJJpKclOQq4ImWhUmSFsa4QXAl8PeA/9N//Hh/myTpODfWFBNV9VW8K1iSTkhjnREkeVWSzye5r9++IMm/bFuaJGkhjDs09B+AnwW+C1BV99C7L0CSdJwbNwhOrar/MbTt8LEuRpK08MYNgkNJXkH/5rIk7wYealaVJGnBjLsewfuBzcB5SfYDe+ndVCZJOs6NGwRfq6ofTXIacFJVPdKyKEnSwhl3aGhvks3ADwCPNqxHkrTAxg2CVwN/QG+IaG+Sm5O8qV1ZkqSFMlYQVNW3q+pTVfV3gdcCLwFub1qZJGlBjL0eQZI3J7mF3qpip9CbckKSdJwb68viJHuBu4BPAR+qqsdaFiVJWjjjXjV0YVV9q2klkqRFcbQVyjZU1Y3AR5LMWTmsqj7YrDJJ0oI42ncED/R/TgF3jngcUZLVSXYnmU5y3RH6vT7JE/07liVJC+hoS1V+tv/0nqr6s2dz4CQTwEbgUmAG2JlkW1XdP6LfR+mtbSxJWmDjXjX0sSRfTnJDkteM+ZpVwHRV7amqx4GtjF7T4APAbcDXxzyuJOkYGvc+grcAlwCzwOYk946xHsFSYN9Ae6a/7WlJlgLvBDZxBEnWJplKMjU7OztOyZKkMY19H0FVHayqjwPr6F1Kev1RXpJRhxlq/zLwM1V1xPWPq2pzVa2sqpWTk5NjVixJGse49xF8H/Ae4N3AN+gN8/zzo7xsBjh7oL0MODDUZyWwNQnAmcDbkxyuqs+MU5ck6fkb9z6C/wh8EnhrVQ3/Yz6fncCKJMuB/fRWNHvGgvdVtfyp50luBX7HEJCkhXXUIOhf1fO/q+pXns2Bq+pwkvX0rgaaALZU1a4k6/r7j/i9gCRpYRw1CKrqiSTfk2RJ/+qfsVXVdmD70LaRAVBV1zybY0uSjo2xF6YB7kiyDXh6nqGq+liTqiRJC2bcIDjQf5wEnN6uHEnSQhsrCKrqX7cuRJK0OMa9fPSPmHsPAFX1w8e8IknSghp3aOjageenAO8CDh/7ciRJC23coaHhmUbvSOJSlZJ0Ahh3aOhlA82T6N0RfFaTiiRJC2rcoaE7+f/fERwGvgq8r0VBkqSFdbQVyl4P7HtqKogkP0Hv+4GvAvcf4aWSpOPE0WYf/ffA4wBJfgj4JeDXgW8Cm9uWJklaCEcbGpqoqof7z98DbK6q24DbktzVtDJJ0oI42hnBRJKnwuJHgD8c2Dfu9wuSpBewo/1j/kng9iSHgG8DXwBI8kp6w0OSpOPc0Rav/0iSzwMvB36/qp66cugkemsNS5KOc+NMQ/2lEdu+0qYcSdJCG3vNYknSickgkKSOaxoESVYn2Z1kOsl1I/avSXJPkruSTCV5U8t6JElzNbsEtL/W8UbgUmAG2JlkW1UN3pH8eWBbVVWSC4BPAee1qkmSNFfLM4JVwHRV7emvdbwVWDPYoaoeHbgS6TRGrHkgSWqrZRAsBfYNtGf6254hyTuTfBn4r8BPjjpQkrX9oaOp2dnZJsVKUle1DIKM2DZqlbP/UlXnAe8Abhh1oKraXFUrq2rl5OTksa1SkjquZRDMAGcPtJcBB+brXFV/ArwiyZkNa5IkDWkZBDuBFUmWJ1kCXA5sG+yQ5JVJ0n/+OmAJ8I2GNUmShjS7aqiqDidZD+wAJoAtVbUrybr+/k301ja4Osl36c1l9J6BL48lSQug6QyiVbUd2D60bdPA848CH21ZgyTpyLyzWJI6ziCQpI4zCCSp4wwCSeo4g0CSOs4gkKSOMwgkqeMMAknqOINAkjrOIJCkjjMIJKnjDAJJ6jiDQJI6ziCQpI5rOg21Xtg2bNjAwYMHOeuss7jxxhsXuxxJi8Qg6LCDBw+yf//+xS5D0iJzaEiSOq5pECRZnWR3kukk143Yf1WSe/qPLya5sGU9kqS5mgVBkglgI3AZcD5wRZLzh7rtBd5cVRcANwCbW9UjSRqt5RnBKmC6qvZU1ePAVmDNYIeq+mJV/d9+80vAsob1SJJGaBkES4F9A+2Z/rb5vA/43Yb1SJJGaHnVUEZsq5Edk7fQC4I3zbN/LbAW4JxzzjlW9UmSaHtGMAOcPdBeBhwY7pTkAuATwJqq+saoA1XV5qpaWVUrJycnmxQrSV3V8oxgJ7AiyXJgP3A5cOVghyTnAJ8G/kFVfaVhLc9w8Yd+Y6He6gXt9EOPMAE8eOgRf0+AO2+6erFLkBZFsyCoqsNJ1gM7gAlgS1XtSrKuv38TcD3wPcAtSQAOV9XKVjVJkuZqemdxVW0Htg9t2zTw/KeAn2pZgyTpyLyzWJI6ziCQpI4zCCSp4wwCSeo4g0CSOs4gkKSOMwgkqeNcoazDnlxy2jN+Suomg6DDHlvx1sUuQdILgENDktRxBoEkdZxBIEkdZxBIUscZBJLUcQaBJHWcQSBJHWcQSFLHGQSS1HFNgyDJ6iS7k0wnuW7E/vOS/GmS7yS5tmUtkqTRmk0xkWQC2AhcCswAO5Nsq6r7B7o9DHwQeEerOiRJR9byjGAVMF1Ve6rqcWArsGawQ1V9vap2At9tWIck6QhaBsFSYN9Ae6a/7VlLsjbJVJKp2dnZY1KcJKmnZRBkxLZ6Lgeqqs1VtbKqVk5OTj7PsiRJg1oGwQxw9kB7GXCg4ftJkp6DlkGwE1iRZHmSJcDlwLaG7ydJeg6aXTVUVYeTrAd2ABPAlqralWRdf/+mJGcBU8BLgCeT/BPg/Kr6Vqu6JEnP1HSFsqraDmwf2rZp4PlBekNGkqRF4p3FktRxBoEkdZxBIEkdZxBIUscZBJLUcQaBJHWcQSBJHWcQSFLHGQSS1HEGgSR1nEEgSR1nEEhSxxkEktRxBoEkdZxBIEkdZxBIUscZBJLUcU2DIMnqJLuTTCe5bsT+JPl4f/89SV7Xsh5J0lzNgiDJBLARuAw4H7giyflD3S4DVvQfa4Ffa1WPJGm0lmcEq4DpqtpTVY8DW4E1Q33WAL9RPV8CXprk5Q1rkiQNabl4/VJg30B7BnjDGH2WAg8Ndkqylt4ZA8CjSXYf21I77Uzg0GIX8UKQf/sTi12CnsnP5lN+IcfiKN87346WQTCq8noOfaiqzcDmY1GUninJVFWtXOw6pGF+NhdOy6GhGeDsgfYy4MBz6CNJaqhlEOwEViRZnmQJcDmwbajPNuDq/tVDPwB8s6oeGj6QJKmdZkNDVXU4yXpgBzABbKmqXUnW9fdvArYDbwemgb8A3tuqHs3LITe9UPnZXCCpmjMkL0nqEO8slqSOMwgkqeMMAj0tySVJfmex69CJIckHkzyQ5DcbHf9fJbm2xbG7puV9BJK67R8Bl1XV3sUuREfmGcEJJsm5Sb6c5BNJ7kvym0l+NMkdSf5XklX9xxeT/Fn/56tHHOe0JFuS7Oz3G54eRJpXkk3AXwe2Jfm5UZ+lJNck+UySzybZm2R9kn/W7/OlJC/r9/vp/mvvTnJbklNHvN8rkvxekjuTfCHJeQv7Kz6+GQQnplcCvwJcAJwHXAm8CbgW+BfAl4EfqqrXAtcD/2bEMX4O+MOqej3wFuCmJKctQO06AVTVOno3h74FOI35P0vfT+/zuQr4CPAX/c/lnwJX9/t8uqpeX1UXAg8A7xvxlpuBD1TVxfQ+57e0+ZWdmBwaOjHtrap7AZLsAj5fVZXkXuBc4Azg15OsoDelx4tGHOOtwN8ZGIM9BTiH3l9E6dmY77ME8EdV9QjwSJJvAp/tb7+X3n9kAL4/yS8CLwVeTO/epKcleTHwN4H/nDw9a81favDrOGEZBCem7ww8f3Kg/SS9P/Mb6P0FfGeSc4E/HnGMAO+qKif40/M18rOU5A0c/bMKcCvwjqq6O8k1wCVDxz8J+POquuiYVt0hDg110xnA/v7za+bpswP4QPr/xUry2gWoSyem5/tZOh14KMmLgKuGd1bVt4C9SX68f/wkufB51twpBkE33Qj8UpI76E3/McoN9IaM7klyX78tPRfP97P088B/Bz5H7/utUa4C3pfkbmAXc9c+0RE4xYQkdZxnBJLUcQaBJHWcQSBJHWcQSFLHGQSS1HEGgfQs9OfN2ZXkniR39W+Kko5r3lksjSnJG4EfA15XVd9JciawZJHLkp43zwik8b0cOFRV3wGoqkNVdSDJxUlu7898uSPJy5OckWT3UzO7Jvlkkp9e1OqleXhDmTSm/uRm/w04FfgD4LeALwK3A2uqajbJe4C3VdVPJrkU+DC9mWCvqarVi1S6dEQODUljqqpHk1wM/CC96ZR/C/hFelMpf64/lc4E8FC//+f6899sBJz7Ri9YnhFIz1GSdwPvB06pqjeO2H8SvbOF5cDbq+qeBS5RGovfEUhjSvLq/hoOT7mI3voMk/0vkknyoiSv6e//p/39VwBb+rNnSi84nhFIY+oPC/0qvQVSDgPTwFpgGfBxetN7nwz8Mr0zgd8GVlXVI0k+BjxSVb+w8JVLR2YQSFLHOTQkSR1nEEhSxxkEktRxBoEkdZxBIEkdZxBIUscZBJLUcf8PqyWQrP0nEGUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.barplot(x='Sex', y='Survived', data = titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Pclass', ylabel='Survived'>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Pclass', y='Survived', hue='Sex', data = titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_cate(age):\n",
    "    cat = ''\n",
    "    if age <= -1 : cat = \"Unknown\"\n",
    "    elif age <=5 : cat = 'Baby'\n",
    "    elif age <=12 : cat = \"Child\"\n",
    "    elif age <= 18 : cat = 'Teenager'\n",
    "    elif age <=25 : cat='Student'\n",
    "    elif age <= 35 : cat = 'Young Adult'\n",
    "    elif age <= 60 : cat = 'Adult'\n",
    "    else : cat = 'Elderly'\n",
    "        \n",
    "    return cat\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "grp_names = [\"Unknown\",'Baby', \"Child\",'Teenager','Student', 'Young Adult', 'Adult', 'Elderly']\n",
    "\n",
    "titanic_df['Age_cat'] = titanic_df[\"Age\"].apply(lambda x : get_cate(x))\n",
    "sns.barplot(x='Age_cat', y='Survived', hue='Sex', order=grp_names, data=titanic_df)\n",
    "titanic_df.drop(\"Age_cat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex   \n",
       "male      577\n",
       "female    314\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df[[\"Sex\"]].value_counts()\n",
    "# titanic_df[[\"Cabin\"]].value_counts()\n",
    "# titanic_df[[\"Embarked\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex\n",
      "['female' 'male']\n",
      "[0 1]\n",
      "\n",
      "Cabin\n",
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'N' 'T']\n",
      "[0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Embarked\n",
      "['C' 'N' 'Q' 'S']\n",
      "[0 1 2 3]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex_cat</th>\n",
       "      <th>Cabin_cat</th>\n",
       "      <th>Embarked_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>N</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex        Age  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.000000   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.000000   \n",
       "2                               Heikkinen, Miss. Laina  female  26.000000   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.000000   \n",
       "4                             Allen, Mr. William Henry    male  35.000000   \n",
       "..                                                 ...     ...        ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.000000   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.000000   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female  29.699118   \n",
       "889                              Behr, Mr. Karl Howell    male  26.000000   \n",
       "890                                Dooley, Mr. Patrick    male  32.000000   \n",
       "\n",
       "     SibSp  Parch            Ticket     Fare Cabin Embarked  Sex_cat  \\\n",
       "0        1      0         A/5 21171   7.2500     N        S        1   \n",
       "1        1      0          PC 17599  71.2833     C        C        0   \n",
       "2        0      0  STON/O2. 3101282   7.9250     N        S        0   \n",
       "3        1      0            113803  53.1000     C        S        0   \n",
       "4        0      0            373450   8.0500     N        S        1   \n",
       "..     ...    ...               ...      ...   ...      ...      ...   \n",
       "886      0      0            211536  13.0000     N        S        1   \n",
       "887      0      0            112053  30.0000     B        S        0   \n",
       "888      1      2        W./C. 6607  23.4500     N        S        0   \n",
       "889      0      0            111369  30.0000     C        C        1   \n",
       "890      0      0            370376   7.7500     N        Q        1   \n",
       "\n",
       "     Cabin_cat  Embarked_cat  \n",
       "0            7             3  \n",
       "1            2             0  \n",
       "2            7             3  \n",
       "3            2             3  \n",
       "4            7             3  \n",
       "..         ...           ...  \n",
       "886          7             3  \n",
       "887          1             3  \n",
       "888          7             3  \n",
       "889          2             0  \n",
       "890          7             2  \n",
       "\n",
       "[891 rows x 15 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LabelEncoding으로 문자열 카테고리 피처를 숫자형으로 변환하기\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_features(dataDF):\n",
    "    features = [\"Sex\",\"Cabin\",\"Embarked\"]\n",
    "    \n",
    "    for feature in features :\n",
    "        cate_dat = dataDF[feature]\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(cate_dat)\n",
    "        dataDF[feature+\"_cat\"] = encoder.transform(cate_dat)\n",
    "        \n",
    "        print(feature)\n",
    "        print(encoder.classes_)\n",
    "        print(encoder.transform(encoder.classes_))\n",
    "        print()\n",
    "    \n",
    "    return dataDF\n",
    "\n",
    "# dataDF = titanic_df.copy()\n",
    "# cate_dat = dataDF[\"Sex\"]\n",
    "\n",
    "# encoder = LabelEncoder()\n",
    "# encoder.fit(cate_dat)\n",
    "# labels = encoder.transform(cate_dat)\n",
    "\n",
    "# dataDF[\"Sex_cat\"]= labels\n",
    "# print(encoder.classes_)\n",
    "# print(encoder.transform(encoder.classes_))\n",
    "# dataDF.head()\n",
    "\n",
    "titanic_encode_df = encode_features(titanic_df)\n",
    "titanic_encode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 과정 함수로 만들기\n",
    "\n",
    "# 결측치처리\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df[\"Age\"].mean(), inplace=True) # Age 평균값 넣어주기\n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Embarked'].fillna(\"N\", inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 필요 없는 열 삭제 - PassengerId, Name, Ticket\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId',\"Name\", \"Ticket\"], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 라벨인코딩 - Cabin, Sex, Embarked \n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    \n",
    "    features = ['Cabin', \"Sex\",'Embarked']\n",
    "    for feature in features :\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(df[feature])\n",
    "        df[feature] = encoder.transform(df[feature])\n",
    "        \n",
    "        print(feature)\n",
    "        print(encoder.classes_)\n",
    "        print(encoder.transform(encoder.classes_))\n",
    "        print()\n",
    "        \n",
    "    return df\n",
    "\n",
    "# 전처리 진행\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cabin\n",
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'N' 'T']\n",
      "[0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "Sex\n",
      "['female' 'male']\n",
      "[0 1]\n",
      "\n",
      "Embarked\n",
      "['C' 'N' 'Q' 'S']\n",
      "[0 1 2 3]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch     Fare  Cabin  Embarked\n",
       "0       3    1  22.0      1      0   7.2500      7         3\n",
       "1       1    0  38.0      1      0  71.2833      2         0\n",
       "2       3    0  26.0      0      0   7.9250      7         3\n",
       "3       1    0  35.0      1      0  53.1000      2         3\n",
       "4       3    1  35.0      0      0   8.0500      7         3"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 피처 데이터 세트와 레이블 세트 추출\n",
    "titanic_df = pd.read_csv(\"./titanic_train.csv\")\n",
    "y_titanic_df = titanic_df[\"Survived\"]\n",
    "X_titanic_df = titanic_df.drop('Survived', axis=1)\n",
    "\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "X_titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 세트 추출\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 알고리즘 종류 및 클래스\n",
    "- 결정트리 DecisionTreeClassifier\n",
    "- 랜덤포레스트 RandomForestClassifier\n",
    "- 로지스틱 회귀 LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7877094972067039\n",
      "0.8547486033519553\n",
      "0.8491620111731844\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dtree = DecisionTreeClassifier(random_state=11)\n",
    "rfor = RandomForestClassifier(random_state =11)\n",
    "lreg = LogisticRegression()\n",
    "\n",
    "# DecisionTree\n",
    "dtree.fit(X_train,y_train)\n",
    "pred = dtree.predict(X_test)\n",
    "dt_acc = accuracy_score(y_test, pred)\n",
    "print(dt_acc)\n",
    "\n",
    "\n",
    "# RandomForest\n",
    "rfor.fit(X_train, y_train)\n",
    "pred = rfor.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test, pred)\n",
    "print(rf_acc)\n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "lreg.fit(X_train,y_train)\n",
    "pred = lreg.predict(X_test)\n",
    "lr_acc = accuracy_score(y_test, pred)\n",
    "print(lr_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0차 검증 정확도 : 0.7541899441340782\n",
      "1차 검증 정확도 : 0.7808988764044944\n",
      "2차 검증 정확도 : 0.7865168539325843\n",
      "3차 검증 정확도 : 0.7696629213483146\n",
      "4차 검증 정확도 : 0.8202247191011236\n",
      "평균 정확도 : 0.782298662984119\n",
      "\n",
      "0차 검증 정확도 : 0.7932960893854749\n",
      "1차 검증 정확도 : 0.8089887640449438\n",
      "2차 검증 정확도 : 0.8370786516853933\n",
      "3차 검증 정확도 : 0.7752808988764045\n",
      "4차 검증 정확도 : 0.8595505617977528\n",
      "평균 정확도 : 0.8148389931579938\n",
      "\n",
      "0차 검증 정확도 : 0.8044692737430168\n",
      "1차 검증 정확도 : 0.7808988764044944\n",
      "2차 검증 정확도 : 0.7752808988764045\n",
      "3차 검증 정확도 : 0.7584269662921348\n",
      "4차 검증 정확도 : 0.8258426966292135\n",
      "평균 정확도 : 0.7889837423890528\n"
     ]
    }
   ],
   "source": [
    "# kfold 이용하기\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def exec_kfold(clf, folds=5):\n",
    "    kfold = KFold(n_splits=folds)\n",
    "    scores = []\n",
    "    \n",
    "    for iter_cnt, (train_idx, test_idx) in enumerate(kfold.split(X_titanic_df)):\n",
    "        \n",
    "        X_train, X_test = X_titanic_df.values[train_idx], X_titanic_df.values[test_idx]\n",
    "        y_train, y_test = y_titanic_df.values[train_idx], y_titanic_df.values[test_idx]\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        pred = clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test, pred)\n",
    "        scores.append(acc)\n",
    "        \n",
    "        print(\"{}차 검증 정확도 : {}\".format(iter_cnt, acc))\n",
    "    \n",
    "    mean_score = np.mean(scores)\n",
    "    print(\"평균 정확도 : {}\".format(mean_score))\n",
    "    \n",
    "exec_kfold(dtree, folds=5)\n",
    "print()\n",
    "exec_kfold(rfor, folds=5)\n",
    "print()\n",
    "exec_kfold(lreg, folds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1차 교차 검증 정확도 : 0.7430167597765364\n",
      "2차 교차 검증 정확도 : 0.7752808988764045\n",
      "3차 교차 검증 정확도 : 0.7921348314606742\n",
      "4차 교차 검증 정확도 : 0.7865168539325843\n",
      "5차 교차 검증 정확도 : 0.8426966292134831\n",
      "평균 정확도 : 0.7879291946519366\n",
      "\n",
      "1차 교차 검증 정확도 : 0.7932960893854749\n",
      "2차 교차 검증 정확도 : 0.797752808988764\n",
      "3차 교차 검증 정확도 : 0.848314606741573\n",
      "4차 교차 검증 정확도 : 0.7640449438202247\n",
      "5차 교차 검증 정확도 : 0.8651685393258427\n",
      "평균 정확도 : 0.8137153976523758\n",
      "\n",
      "1차 교차 검증 정확도 : 0.7988826815642458\n",
      "2차 교차 검증 정확도 : 0.7696629213483146\n",
      "3차 교차 검증 정확도 : 0.7808988764044944\n",
      "4차 교차 검증 정확도 : 0.7752808988764045\n",
      "5차 교차 검증 정확도 : 0.797752808988764\n",
      "평균 정확도 : 0.7844956374364446\n"
     ]
    }
   ],
   "source": [
    "# cross_val_score() 이용하기 - StratifiedKFold \n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(dtree, X_titanic_df, y_titanic_df, cv=5)\n",
    "for iter_cnt, acc in enumerate(scores):\n",
    "    print(\"{}차 교차 검증 정확도 : {}\".format(iter_cnt+1, acc))\n",
    "    \n",
    "print(\"평균 정확도 : {}\".format(np.mean(scores)))\n",
    "print()\n",
    "\n",
    "scores = cross_val_score(rfor, X_titanic_df, y_titanic_df, cv=5)\n",
    "for iter_cnt, acc in enumerate(scores):\n",
    "    print(\"{}차 교차 검증 정확도 : {}\".format(iter_cnt+1, acc))\n",
    "    \n",
    "print(\"평균 정확도 : {}\".format(np.mean(scores)))\n",
    "print()\n",
    "\n",
    "scores = cross_val_score(lreg, X_titanic_df, y_titanic_df, cv=5)\n",
    "for iter_cnt, acc in enumerate(scores):\n",
    "    print(\"{}차 교차 검증 정확도 : {}\".format(iter_cnt+1, acc))\n",
    "    \n",
    "print(\"평균 정확도 : {}\".format(np.mean(scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action= 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8715083798882681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'max_depth':[2,3,5,10], 'min_samples_split':[2,3,5], 'min_samples_leaf':[1,5,8]}\n",
    "\n",
    "grid_dclf = GridSearchCV(dtree, param_grid=params, scoring='accuracy', cv=5)\n",
    "grid_dclf.fit(X_train, y_train)\n",
    "\n",
    "print(grid_dclf.best_params_)\n",
    "best_dclf = grid_dclf.best_estimator_\n",
    "\n",
    "dpred = best_dclf.predict(X_test)\n",
    "acc = accuracy_score(y_test, dpred)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
