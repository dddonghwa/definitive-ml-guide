{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_new_feature_name_df(old_feature_name_df):\n",
    "    feature_dup_df = pd.DataFrame(data=old_feature_name_df.groupby('column_name').cumcount(), columns=['dup_cnt'])\n",
    "    feature_dup_df = feature_dup_df.reset_index()\n",
    "    new_feature_name_df = pd.merge(old_feature_name_df.reset_index(), feature_dup_df, how='outer')\n",
    "    new_feature_name_df['column_name'] = new_feature_name_df[['column_name', 'dup_cnt']].apply(lambda x : x[0]+'_'+str(x[1]) \n",
    "                                                                                           if x[1] >0 else x[0] ,  axis=1)\n",
    "    new_feature_name_df = new_feature_name_df.drop(['index'], axis=1)\n",
    "    return new_feature_name_df\n",
    "\n",
    "def get_human_dataset( ):\n",
    "    \n",
    "    # 각 데이터 파일들은 공백으로 분리되어 있으므로 read_csv에서 공백 문자를 sep으로 할당.\n",
    "    feature_name_df = pd.read_csv('./human_activity/features.txt',sep='\\s+',\n",
    "                        header=None,names=['column_index','column_name'])\n",
    "    \n",
    "    # 중복된 feature명을 새롭게 수정하는 get_new_feature_name_df()를 이용하여 새로운 feature명 DataFrame생성. \n",
    "    new_feature_name_df = get_new_feature_name_df(feature_name_df)\n",
    "    \n",
    "    # DataFrame에 피처명을 컬럼으로 부여하기 위해 리스트 객체로 다시 변환\n",
    "    feature_name = new_feature_name_df.iloc[:, 1].values.tolist()\n",
    "    \n",
    "    # 학습 피처 데이터 셋과 테스트 피처 데이터을 DataFrame으로 로딩. 컬럼명은 feature_name 적용\n",
    "    X_train = pd.read_csv('./human_activity/train/X_train.txt',sep='\\s+', names=feature_name )\n",
    "    X_test = pd.read_csv('./human_activity/test/X_test.txt',sep='\\s+', names=feature_name)\n",
    "    \n",
    "    # 학습 레이블과 테스트 레이블 데이터을 DataFrame으로 로딩하고 컬럼명은 action으로 부여\n",
    "    y_train = pd.read_csv('./human_activity/train/y_train.txt',sep='\\s+',header=None,names=['action'])\n",
    "    y_test = pd.read_csv('./human_activity/test/y_test.txt',sep='\\s+',header=None,names=['action'])\n",
    "    \n",
    "    # 로드된 학습/테스트용 DataFrame을 모두 반환 \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. GBM(Gradient Boosting Machine)\n",
    "\n",
    "### 부스팅 알고리즘\n",
    "- 여러 개의 약한 학습기를 순차적으로 학습-예측하면서 잘못 예측한 데이터에 가중치를 부여하며 오류를 개선해나가는 모델\n",
    "- (예) AdaBoost, Gradient Bosst\n",
    "\n",
    "### GBM\n",
    "- 랜덤포레스트 기반\n",
    "- AdaBoost와 유사하나 가중치 업데이트를 <U>경사 하강법</U>을 이용  \n",
    "- $error = y - F(x)$ 을 최소화하는 방향성을 가지고 반복적으로 가중치 값을 업데이트\n",
    "\n",
    "#### 1. 장점\n",
    "- 랜덤포레스트보다 더 나은 에측 성능\n",
    "\n",
    "#### 2. 단점\n",
    "- 시간이 오래 걸리고, 하이퍼 파라미터 튜닝 노력이 더 필요\n",
    "- 과적합 규제(regulation)가 없음\n",
    "\n",
    "*파이썬 라이브러리를 활용한 머신러닝 교재에 어떤 모델을 기반으로 하는지 등 더 자세하게 나와있는 것 같다! [참고링크](https://jhryu1208.github.io/data/2020/11/21/ML_bagging-extra-ada/)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING : this code takes so long\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "gbm = GradientBoostingClassifier(random_state=0)\n",
    "gbm.fit(X_train, y_train)\n",
    "pred = gbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9393\n",
      "time : 579.7\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy : {:.4f}\".format(accuracy_score(y_test, pred)))\n",
    "print(\"time : {:.1f}\".format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM 하이퍼 파라미터 튜닝\n",
    "```\n",
    "class sklearn.ensemble.GradientBoostingClassifier(*, loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)[source]\n",
    "```\n",
    "\n",
    "- `loss `(default='deviation) : 손실함수, 특별한 이유가 없으면 그대로 적용 ('exponential'=AdaBoost algorithm??[링크](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html))\n",
    "- `learning_rate`(default=0.1) : weak learner가 순차적으로 오류 값을 보정해 나가는데 적용하는 계수, (0~1), n_estimator와 상호 보완적으로 조합해 사용\n",
    "- `n_estimator`(default=100) : weak learner의 갯수, 갯수가 많을수록 시간↑\n",
    "- `subsample`(default=1) : weak learner가 학습에 사용하는 데이터 샘플링 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "start_time = time.time()\n",
    "params = {\n",
    "    \"n_estimators\":[100,500],\n",
    "    \"learning_rate\":[0.05,0.1]\n",
    "}\n",
    "\n",
    "gbm = GradientBoostingClassifier()\n",
    "grid_gbm = GridSearchCV(gbm, param_grid=params, cv=2, verbose=1)\n",
    "grid_gbm.fit(X_train, y_train)\n",
    "\n",
    "print(\"best hyper-params : \", grid_gbm.best_params_)\n",
    "print(\"best score : \", grid_gbm.best_score_)\n",
    "print(\"time : \", time.time()- start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid_gbm.best_estimator_.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(\"acc : {:.4f}\".format( acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
